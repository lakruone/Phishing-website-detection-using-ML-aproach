{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML and Javascript Based Features\n",
    "- Links in Meta, Script and Link tags\n",
    "- Submitting Information to Email\n",
    "- Abnormal URL\n",
    "- Website Forwarding\n",
    "- status Bar Customization\n",
    "- Disabling Right Click\n",
    "- Using Pop-up Window\n",
    "- IFrame Redirection\n",
    "\n",
    "Eeach of these features are explained below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Links in Meta, Script and Link tags\n",
    "Here, check whether the links in Meta, scrypt and link tags are linked to the same domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "from tldextract import extract\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "output = os.path.join('output.csv')\n",
    "urlinput = pd.read_csv('links.csv')\n",
    "\n",
    "f = csv.writer(open(output, \"w+\", newline=\"\\n\", encoding=\"utf-8\"))\n",
    "f.writerow([\"URL\", \"links_in_tags\"])\n",
    "\n",
    "for i in range(0,len(urlinput)):\n",
    "    url = urlinput.loc[i,'url']\n",
    "\n",
    "    try:\n",
    "        subDomain, domain, suffix = extract(url)\n",
    "        websiteDomain = domain\n",
    "\n",
    "        opener = urllib.request.urlopen(url).read()\n",
    "        soup = BeautifulSoup(opener, 'lxml')\n",
    "\n",
    "        metas = soup.find_all('meta',href=True)\n",
    "        links = soup.find_all('link', href=True)\n",
    "        scripts = soup.find_all('script', src=True)\n",
    "\n",
    "        no_of_meta = len(metas)\n",
    "        no_of_link = len(links)\n",
    "        no_of_script = len(scripts)\n",
    "        total = no_of_meta + no_of_link + no_of_script\n",
    "\n",
    "        linked_to_same = 0\n",
    "        avg =0\n",
    "\n",
    "        for meta in metas:\n",
    "            subDomain, domain, suffix = extract(meta['href'])\n",
    "            meta_domain = domain\n",
    "\n",
    "            if(websiteDomain == meta_domain or meta_domain == \"\"):\n",
    "                linked_to_same = linked_to_same+1\n",
    "\n",
    "        for link in links:\n",
    "            subDomain, domain, suffix = extract(link['href'])\n",
    "            link_domain = domain\n",
    "            if(websiteDomain == link_domain or link_domain == \"\"):\n",
    "                linked_to_same = linked_to_same + 1\n",
    "\n",
    "        for script in scripts:\n",
    "            subDomain, domain, suffix = extract(script['src'])\n",
    "            script_domain = domain\n",
    "            if(websiteDomain == script_domain or script_domain == \"\"):\n",
    "                linked_to_same = linked_to_same + 1\n",
    "\n",
    "        outside_domain = total - linked_to_same\n",
    "\n",
    "        if(total!=0):\n",
    "            avg = round((outside_domain/total)*100,2)\n",
    "\n",
    "        f.writerow([url,avg])\n",
    "        print(str(i)+\" - Response : \"+str(avg)+\" - \"+url)\n",
    "\n",
    "    except:\n",
    "        f.writerow([url,\"N/A\"])\n",
    "        print(str(i)+\" - Response : N/A - \"+url)\n",
    "        # raised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting Information to Email\n",
    "Web forms may allow user to submit his personal information to an email. Here, the availability of 'mail()' function or 'mailto()' function is recorded.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "\n",
    "output = os.path.join('output.csv')\n",
    "urlinput = pd.read_csv('links.csv')\n",
    "\n",
    "f = csv.writer(open(output, \"w+\", newline=\"\\n\", encoding=\"utf-8\"))\n",
    "f.writerow([\"URL\", \"submit_to_email\"])\n",
    "\n",
    "for i in range(0,len(urlinput)):\n",
    "    url = urlinput.loc[i,'url']\n",
    "\n",
    "    # Stores the response of the given URL\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "    except:\n",
    "        response = \"\"\n",
    "        # raise\n",
    "\n",
    "    if response != \"\" :\n",
    "        if re.findall(r\"[mail\\(\\)|mailto:?]\", response.text):\n",
    "            result = 1\n",
    "        else:\n",
    "            result = -1\n",
    "    else:\n",
    "        result = \"N/A\"\n",
    "\n",
    "    f.writerow([url,result])\n",
    "    print(str(i)+\" - Response : \"+str(result)+\" - \"+url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abnormal URL\n",
    "The host name availability is checked in the given URL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "\n",
    "output = os.path.join('output.csv')\n",
    "urlinput = pd.read_csv('links.csv')\n",
    "\n",
    "f = csv.writer(open(output, \"w+\", newline=\"\\n\", encoding=\"utf-8\"))\n",
    "f.writerow([\"URL\", \"abnormal\"])\n",
    "\n",
    "for i in range(0,len(urlinput)):\n",
    "    url = urlinput.loc[i,'url']\n",
    "\n",
    "    # Stores the response of the given URL\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "    except:\n",
    "        response = \"\"\n",
    "        # raise\n",
    "\n",
    "    if response != \"\" :\n",
    "        if response.text == \"\":\n",
    "            result = 1\n",
    "        else:\n",
    "            result = -1\n",
    "    else:\n",
    "        result = \"N/A\"\n",
    "\n",
    "    f.writerow([url,result])\n",
    "    print(str(i)+\" - Response : \"+str(result)+\" - \"+url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Website Forwarding\n",
    "Number of redirections of the website is counted here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "\n",
    "output = os.path.join('output.csv')\n",
    "urlinput = pd.read_csv('links.csv')\n",
    "\n",
    "f = csv.writer(open(output, \"w+\", newline=\"\\n\", encoding=\"utf-8\"))\n",
    "f.writerow([\"URL\", \"redirect\"])\n",
    "\n",
    "for i in range(0,len(urlinput)):\n",
    "    url = urlinput.loc[i,'url']\n",
    "\n",
    "    # Stores the response of the given URL\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "    except:\n",
    "        response = \"\"\n",
    "        # raise\n",
    "\n",
    "    if response != \"\" :\n",
    "        result = len(response.history)\n",
    "    else:\n",
    "        result = \"N/A\"\n",
    "\n",
    "    f.writerow([url,result])\n",
    "    print(str(i)+\" - Response : \"+str(result)+\" - \"+url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Status Bar Customization\n",
    "There can be javascripts to show fake url in the status bar. So that, particularly the “onMouseOver” event is serached in the source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "\n",
    "output = os.path.join('output.csv')\n",
    "urlinput = pd.read_csv('links.csv')\n",
    "\n",
    "f = csv.writer(open(output, \"w+\", newline=\"\\n\", encoding=\"utf-8\"))\n",
    "f.writerow([\"URL\", \"status_bar\"])\n",
    "\n",
    "for i in range(0,len(urlinput)):\n",
    "    url = urlinput.loc[i,'url']\n",
    "\n",
    "    # Stores the response of the given URL\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "    except:\n",
    "        response = \"\"\n",
    "        # raise\n",
    "\n",
    "    if response != \"\" :\n",
    "        if re.findall(\"<script>.+onmouseover.+</script>\", response.text):\n",
    "            result = 1\n",
    "        else:\n",
    "            result = -1\n",
    "    else:\n",
    "        result = -1\n",
    "\n",
    "    f.writerow([url,result])\n",
    "    print(str(i)+\" - Response : \"+str(result)+\" - \"+url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Disabling Right Click\n",
    "There can be JavaScript to disable the right-click function, so that users cannot view and save the webpage source code. For this feature, we search for event “event.button==2” in the webpage source code and check if the right click is disabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "\n",
    "output = os.path.join('output.csv')\n",
    "urlinput = pd.read_csv('links.csv')\n",
    "\n",
    "f = csv.writer(open(output, \"w+\", newline=\"\\n\", encoding=\"utf-8\"))\n",
    "f.writerow([\"URL\", \"disble_write_click\"])\n",
    "\n",
    "for i in range(0,len(urlinput)):\n",
    "    url = urlinput.loc[i,'url']\n",
    "\n",
    "    # Stores the response of the given URL\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "    except:\n",
    "        response = \"\"\n",
    "        # raise\n",
    "\n",
    "    if response != \"\" :\n",
    "        if re.findall(r\"event.button ?== ?2\", response.text):\n",
    "            result = 1\n",
    "        else:\n",
    "            result = -1\n",
    "    else:\n",
    "        result = -1\n",
    "\n",
    "    f.writerow([url,result])\n",
    "    print(str(i)+\" - Response : \"+str(result)+\" - \"+url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Pop-up Window\n",
    "Here, the availability of text fields in the popup window is searched "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "\n",
    "output = os.path.join('output.csv')\n",
    "urlinput = pd.read_csv('links.csv')\n",
    "\n",
    "f = csv.writer(open(output, \"w+\", newline=\"\\n\", encoding=\"utf-8\"))\n",
    "f.writerow([\"URL\", \"popup\"])\n",
    "\n",
    "for i in range(0,len(urlinput)):\n",
    "    url = urlinput.loc[i,'url']\n",
    "\n",
    "    # Stores the response of the given URL\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "    except:\n",
    "        response = \"\"\n",
    "        # raise\n",
    "\n",
    "    if response != \"\" :\n",
    "        if re.findall(r\"alert\\(\", response.text):\n",
    "            result = 1\n",
    "        else:\n",
    "            result = -1\n",
    "    else:\n",
    "        result = -1\n",
    "\n",
    "    f.writerow([url,result])\n",
    "    print(str(i)+\" - Response : \"+str(result)+\" - \"+url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IFrame Redirection\n",
    "IFrame can be used by making it invisible without frame borders. Here we check whether the source code includes frameBorder attribute for hiding Iframe border."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "\n",
    "output = os.path.join('output.csv')\n",
    "urlinput = pd.read_csv('links.csv')\n",
    "\n",
    "f = csv.writer(open(output, \"w+\", newline=\"\\n\", encoding=\"utf-8\"))\n",
    "f.writerow([\"URL\", \"iframe\"])\n",
    "\n",
    "for i in range(0,len(urlinput)):\n",
    "    url = urlinput.loc[i,'url']\n",
    "\n",
    "    # Stores the response of the given URL\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "    except:\n",
    "        response = \"\"\n",
    "        # raise\n",
    "\n",
    "    if response != \"\" :\n",
    "        if re.findall(r\"[<iframe>|<frameBorder>]\", response.text):\n",
    "            result = 1\n",
    "        else:\n",
    "            result = -1\n",
    "    else:\n",
    "        result = -1\n",
    "\n",
    "    f.writerow([url,result])\n",
    "    print(str(i)+\" - Response : \"+str(result)+\" - \"+url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
